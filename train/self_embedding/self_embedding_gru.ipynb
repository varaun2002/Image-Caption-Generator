{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import warnings\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data():\n",
    "    with open(\"../../data/x.txt\") as f:\n",
    "        x_file = f.readlines()\n",
    "\n",
    "    with open(\"../../data/y.txt\") as f:\n",
    "        y_file = f.readlines()\n",
    "\n",
    "    x_list = []\n",
    "    y_list_temp = []\n",
    "\n",
    "    for x_val, y_val in zip(x_file, y_file):\n",
    "        x_list.append((x_val.split(\", \\n\")[0]))\n",
    "        y_list_temp.append((y_val.split(\" \\n\")[0]))\n",
    "\n",
    "    y_list = []\n",
    "    for y in y_list_temp:\n",
    "        x = y\n",
    "        x = ast.literal_eval(x)\n",
    "        y_list.append(x)\n",
    "\n",
    "    x_list_clean = []\n",
    "    y_list_clean = []\n",
    "\n",
    "    for x in x_list:\n",
    "        x = re.sub(r'[^\\w\\s]', '', x)\n",
    "        x = x.lower()\n",
    "        x_list_clean.append(x)\n",
    "\n",
    "    for y in y_list:\n",
    "        for i in range(len(y)):\n",
    "            y[i] = re.sub(r'[^\\w\\s]', '', y[i])\n",
    "            y[i] = y[i].lower()\n",
    "        y_list_clean.append(y)\n",
    "\n",
    "    return x_list_clean, y_list_clean\n",
    "\n",
    "x_text, y_text = load_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_word2idx = {}\n",
    "x_idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "x_word2count = {}\n",
    "x_n_words = 2 # Count SOS and EOS\n",
    "\n",
    "for x in x_text:\n",
    "    for word in x.split():\n",
    "        if word not in x_word2idx:\n",
    "            x_word2idx[word] = x_n_words\n",
    "            x_idx2word[x_n_words] = word\n",
    "            x_n_words += 1\n",
    "            x_word2count[word] = 1\n",
    "        else:\n",
    "            x_word2count[word] += 1\n",
    "\n",
    "x_lookup = []\n",
    "\n",
    "for x in x_text:\n",
    "    x_lookup_sentence = [x_word2idx[word] for word in x.split()]\n",
    "    x_lookup_sentence.append(EOS_token)\n",
    "    x_lookup.append(x_lookup_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_word2idx = {}\n",
    "y_idx2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "y_word2count = {}\n",
    "y_n_words = 2 # Count SOS and EOS\n",
    "\n",
    "for y in y_text:\n",
    "    for i in range(len(y)):\n",
    "        for word in y[i].split():\n",
    "            if word not in y_word2idx:\n",
    "                y_word2idx[word] = y_n_words\n",
    "                y_idx2word[y_n_words] = word\n",
    "                y_n_words += 1\n",
    "                y_word2count[word] = 1\n",
    "            else:\n",
    "                y_word2count[word] += 1\n",
    "\n",
    "y_lookup = []\n",
    "\n",
    "for y in y_text:\n",
    "    y_lookup_temp = []\n",
    "    for i in range(len(y)):\n",
    "        y_lookup_sentence = [y_word2idx[word] for word in y[i].split()]\n",
    "        y_lookup_sentence.append(EOS_token)\n",
    "        y_lookup_temp.append(y_lookup_sentence)\n",
    "    y_lookup.append(y_lookup_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lookup_train = x_lookup[:int(len(x_lookup)*0.8)]\n",
    "x_lookup_val = x_lookup[int(len(x_lookup)*0.8):int(len(x_lookup)*0.9)]\n",
    "x_lookup_test = x_lookup[int(len(x_lookup)*0.9):]\n",
    "\n",
    "y_lookup_train = y_lookup[:int(len(y_lookup)*0.8)]\n",
    "y_lookup_val = y_lookup[int(len(y_lookup)*0.8):int(len(y_lookup)*0.9)]\n",
    "y_lookup_test = y_lookup[int(len(y_lookup)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookup_tensors(index):\n",
    "    '''Returns a tuple of tensors (x, y) where x is a tensor of shape (seq_len, 1) and y is a list of tensors of shape (seq_len, 1) of length 5.'''\n",
    "    y_lookup_tensor_list = [torch.tensor(y_lookup[1][i], device=device).view(-1, 1) for i in range(len(y_lookup[index]))]\n",
    "    x_lookup_tensor = torch.tensor(x_lookup[index], device=device).view(-1, 1)\n",
    "    return x_lookup_tensor, y_lookup_tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(x_n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, y_n_words).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train_step(x_batch, y_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    batch_loss = 0\n",
    "\n",
    "    for i in range(len(x_batch)):\n",
    "        x = x_batch[i]\n",
    "        y = y_batch[i]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        loss = 0\n",
    "\n",
    "        input_length = len(x)\n",
    "        n_captions = len(y)\n",
    "\n",
    "        for ei in range(input_length):            \n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x[ei], device=device), encoder_hidden)\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(n_captions):\n",
    "            teacher_forcing = True if random.random() < 0.5 else False\n",
    "            \n",
    "            for word_index in y[di]:\n",
    "                if teacher_forcing:\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    loss += criterion(decoder_output, torch.tensor(word_index, device=device).view(-1))\n",
    "                    decoder_input = torch.tensor(word_index, device=device)\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    loss += criterion(decoder_output, torch.tensor(word_index, device=device).view(-1))\n",
    "                    topv, topi = decoder_output.topk(1)\n",
    "                    decoder_input = topi.squeeze().detach()\n",
    "            \n",
    "        loss = loss / n_captions\n",
    "        batch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "    \n",
    "    return batch_loss / len(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(x_val, y_val, encoder, decoder, criterion, target_length=50):\n",
    "    val_loss = 0\n",
    "\n",
    "    for i in range(len(x_val)):\n",
    "        val_loss_i = 0\n",
    "        x = x_val[i]\n",
    "        y = y_val[i]\n",
    "        input_length = len(x)\n",
    "        n_captions = len(y)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x[ei], device=device), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        for di in range(n_captions):\n",
    "            for dj in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                y_di_dj = y[di][dj] if dj < len(y[di]) else EOS_token\n",
    "                val_loss_i += criterion(decoder_output, torch.tensor(y_di_dj, device=device).view(-1))\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        val_loss_i = val_loss_i / n_captions\n",
    "        val_loss += val_loss_i.item()\n",
    "    \n",
    "    return val_loss / len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 2\n",
    "num_batches = len(x_lookup_train) // batch_size\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        x_batch = x_lookup_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        y_batch = y_lookup_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        batch_loss = batch_train_step(x_batch, y_batch, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        epoch_loss += batch_loss / num_batches\n",
    "        print(f\"Epoch: {epoch+1}/{num_epochs} | Batch: {batch+1}/{num_batches} | Loss: {batch_loss}\")\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        val_loss = val_step(x_lookup_val, y_lookup_val, encoder, decoder, criterion)\n",
    "        print(f\"Epoch: {epoch} / {num_epochs} \\t Epoch Loss: {epoch_loss:.3f} \\t Val Loss: {val_loss:.3f}\")        \n",
    "    \n",
    "    train_loss_list.append(epoch_loss)\n",
    "    val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y, x_idx2word, y_idx2word, encoder, decoder, target_length=50):\n",
    "    for i in range(len(x)):\n",
    "        x_i = x[i]\n",
    "        y_i = y[i]\n",
    "        input_length = len(x_i)\n",
    "        n_captions = len(y_i)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x_i[ei], device=device), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_sentences = []\n",
    "\n",
    "        for di in range(n_captions):\n",
    "            decoded_words = []\n",
    "            for dj in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoded_words.append(y_idx2word[topi.item()])\n",
    "                if topi.item() == EOS_token:\n",
    "                    is_eos = True\n",
    "                    break\n",
    "                else:\n",
    "                    is_eos = False\n",
    "\n",
    "            predicted_sentence = ' '.join(decoded_words)\n",
    "            decoded_sentences.append(predicted_sentence)\n",
    "            if is_eos:\n",
    "                break\n",
    "            \n",
    "        input_text = ' '.join([x_idx2word[word] for word in x_i])\n",
    "        target_text = ' '.join([y_idx2word[word] for word in y_i[0]])\n",
    "\n",
    "        print(f\"input: {input_text}\")\n",
    "        print(f\"target: {target_text}\")\n",
    "        print(f\"predicted: {decoded_sentences[0]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly(x_idx2word, y_idx2word, encoder, decoder, n=1):\n",
    "    for i in range(n):\n",
    "        rand_int = np.random.randint(0, len(x_lookup_val))\n",
    "        x_i = x_lookup_val[rand_int]\n",
    "        y_i = y_lookup_val[rand_int]\n",
    "\n",
    "        evaluate([x_i], [y_i], x_idx2word, y_idx2word, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test, y_test, encoder, decoder, x_idx2word, y_idx2word, target_length=50):\n",
    "    test_loss = 0\n",
    "    test_results = []\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        test_loss_i = 0\n",
    "        x = x_test[i]\n",
    "        y = y_test[i]\n",
    "        input_length = len(x)\n",
    "        n_captions = len(y)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x[ei], device=device), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_sentences = []\n",
    "\n",
    "        for di in range(n_captions):\n",
    "            decoded_words = []\n",
    "            for dj in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                y_di_dj = y[di][dj] if dj < len(y[di]) else EOS_token\n",
    "                test_loss_i += criterion(decoder_output, torch.tensor(y_di_dj, device=device).view(-1))\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "                if topi.item() == EOS_token:\n",
    "                    is_eos = True\n",
    "                    decoded_words.append('<EOS>')\n",
    "                    break\n",
    "                else:\n",
    "                    is_eos = False\n",
    "                    decoded_words.append(y_idx2word[topi.item()])\n",
    "                \n",
    "            predicted_sentence = ' '.join(decoded_words)\n",
    "            decoded_sentences.append(predicted_sentence)\n",
    "            if is_eos:\n",
    "                break\n",
    "\n",
    "        test_loss_i = test_loss_i / n_captions\n",
    "        test_loss += test_loss_i.item()\n",
    "\n",
    "        input_text = ' '.join([x_idx2word[word] for word in x])\n",
    "        target_text = ' '.join([y_idx2word[word] for word in y[0]])\n",
    "        predicted_text = decoded_sentences[0]\n",
    "\n",
    "        test_result_i = (input_text, target_text, predicted_text)\n",
    "        test_results.append(test_result_i)\n",
    "\n",
    "    return test_loss / len(x_test), test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(x_lookup_val, y_lookup_val, x_idx2word, y_idx2word, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_randomly(x_idx2word, y_idx2word, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = test(x_lookup_test, y_lookup_test, encoder, decoder, x_idx2word, y_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_captioning_cleaned_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
