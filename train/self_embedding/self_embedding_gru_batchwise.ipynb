{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import warnings\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from torchmetrics.functional import bleu_score\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_text_data():\n",
    "    with open(\"../../data/x.txt\") as f:\n",
    "        x_file = f.readlines()\n",
    "\n",
    "    with open(\"../../data/y.txt\") as f:\n",
    "        y_file = f.readlines()\n",
    "\n",
    "    x_list = []\n",
    "    y_list_temp = []\n",
    "\n",
    "    for x_val, y_val in zip(x_file, y_file):\n",
    "        x_list.append((x_val.split(\", \\n\")[0]))\n",
    "        y_list_temp.append((y_val.split(\" \\n\")[0]))\n",
    "\n",
    "    y_list = []\n",
    "    for y in y_list_temp:\n",
    "        x = y\n",
    "        x = ast.literal_eval(x)\n",
    "        y_list.append(x)\n",
    "\n",
    "    x_list_clean = []\n",
    "    y_list_clean = []\n",
    "\n",
    "    for x in x_list:\n",
    "        x = re.sub(r'[^\\w\\s]', '', x)\n",
    "        x = x.lower()\n",
    "        x_list_clean.append(x)\n",
    "\n",
    "    for y in y_list:\n",
    "        for i in range(len(y)):\n",
    "            y[i] = re.sub(r'[^\\w\\s]', '', y[i])\n",
    "            y[i] = y[i].lower()\n",
    "        y_list_clean.append(y)\n",
    "\n",
    "    return x_list_clean, y_list_clean\n",
    "\n",
    "x_text, y_text = load_text_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_word2idx = {}\n",
    "x_idx2word = {0: \"<SOS>\", 1: \"<EOS>\"}\n",
    "x_word2count = {}\n",
    "x_n_words = 2 # Count SOS and EOS\n",
    "\n",
    "for x in x_text:\n",
    "    for word in x.split():\n",
    "        if word not in x_word2idx:\n",
    "            x_word2idx[word] = x_n_words\n",
    "            x_idx2word[x_n_words] = word\n",
    "            x_n_words += 1\n",
    "            x_word2count[word] = 1\n",
    "        else:\n",
    "            x_word2count[word] += 1\n",
    "\n",
    "x_lookup = []\n",
    "\n",
    "for x in x_text:\n",
    "    x_lookup_sentence = [x_word2idx[word] for word in x.split()]\n",
    "    x_lookup_sentence.append(EOS_token)\n",
    "    x_lookup.append(x_lookup_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_word2idx = {}\n",
    "y_idx2word = {0: \"<SOS>\", 1: \"<EOS>\"}\n",
    "y_word2count = {}\n",
    "y_n_words = 2 # Count SOS and EOS\n",
    "\n",
    "for y in y_text:\n",
    "    for i in range(len(y)):\n",
    "        for word in y[i].split():\n",
    "            if word not in y_word2idx:\n",
    "                y_word2idx[word] = y_n_words\n",
    "                y_idx2word[y_n_words] = word\n",
    "                y_n_words += 1\n",
    "                y_word2count[word] = 1\n",
    "            else:\n",
    "                y_word2count[word] += 1\n",
    "\n",
    "y_lookup = []\n",
    "\n",
    "for y in y_text:\n",
    "    y_lookup_temp = []\n",
    "    for i in range(len(y)):\n",
    "        y_lookup_sentence = [y_word2idx[word] for word in y[i].split()]\n",
    "        y_lookup_sentence.append(EOS_token)\n",
    "        y_lookup_temp.append(y_lookup_sentence)\n",
    "    y_lookup.append(y_lookup_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lookup_train = x_lookup[:int(len(x_lookup)*0.8)]\n",
    "x_lookup_val = x_lookup[int(len(x_lookup)*0.8):int(len(x_lookup)*0.9)]\n",
    "x_lookup_test = x_lookup[int(len(x_lookup)*0.9):]\n",
    "\n",
    "y_lookup_train = y_lookup[:int(len(y_lookup)*0.8)]\n",
    "y_lookup_val = y_lookup[int(len(y_lookup)*0.8):int(len(y_lookup)*0.9)]\n",
    "y_lookup_test = y_lookup[int(len(y_lookup)*0.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookup_tensors(index, mode):\n",
    "    if mode == 'train':\n",
    "        x = x_lookup_train[index]\n",
    "        y = y_lookup_train[index]\n",
    "    elif mode == 'val':\n",
    "        x = x_lookup_val[index]\n",
    "        y = y_lookup_val[index]\n",
    "    elif mode == 'test':\n",
    "        x = x_lookup_test[index]\n",
    "        y = y_lookup_test[index]\n",
    "\n",
    "    # x = torch.tensor(x, dtype=torch.long, device=device).view(-1, 1)\n",
    "    # y = torch.tensor(y, dtype=torch.long, device=device).view(-1, 1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder = EncoderRNN(x_n_words, hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, y_n_words).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder total parameters: 444,160\n",
      "Decoder total parameters: 4,150,938\n"
     ]
    }
   ],
   "source": [
    "encoder_total_params = sum(p.numel() for p in encoder.parameters() if p.requires_grad)\n",
    "decoder_total_params = sum(p.numel() for p in decoder.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'Encoder total parameters: {encoder_total_params:,}')\n",
    "print(f'Decoder total parameters: {decoder_total_params:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train_step(x_batch, y_batch, encoder, decoder, criterion):\n",
    "    multi_ex_loss_list = []\n",
    "    for ex_index, (x, y) in enumerate(zip(x_batch, y_batch)):\n",
    "        '''\n",
    "        x: 1-D list of length N; N = Variable Length\n",
    "        y: 2-D list of shape (5, N); N = Variable Length\n",
    "        \n",
    "        For each input tuple (x, y), we are generating 5 sentences for x.\n",
    "        Where, each sentence is generated 1 word at a time.\n",
    "        Each predicted sentence would have the same length as the y[i] -- the caption \n",
    "        that it is being compared with.\n",
    "        \n",
    "        Then, NLLLoss is applied on this output sentence vs y[i] -- 1 sentence at a time\n",
    "        for 5 sentences for each example (x, y).\n",
    "        Mean of these 5 values is taken to get the final loss per example (x, y).\n",
    "        \n",
    "        Now, per batch (x_batch, y_batch), this loss is calculated and the mean of this batch\n",
    "        loss is used for BACKPROP. \n",
    "        This allows us to implement batch-wise training and helps converge faster.\n",
    "        '''\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        for i in range(len(x)):\n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x[i], device=device), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor(SOS_token, device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        sentence_loss_list = []\n",
    "\n",
    "        for i in range(len(y)):\n",
    "            sentence_output = torch.empty(1, decoder.output_size, device=device)\n",
    "            teacher_forcing = True if random.random() < 0.5 else False\n",
    "\n",
    "            for j in range(len(y[i])):\n",
    "                if teacher_forcing:\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    sentence_output = torch.cat((sentence_output, decoder_output), dim=0)\n",
    "                    decoder_input = torch.tensor(y[i][j], device=device)\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    sentence_output = torch.cat((sentence_output, decoder_output), dim=0)\n",
    "                    topv, topi = decoder_output.topk(1)\n",
    "                    decoder_input = topi.squeeze().detach()\n",
    "\n",
    "            sentence_output = sentence_output[1:]\n",
    "            sentence_loss = criterion(sentence_output, torch.tensor(y[i], device=device))\n",
    "            sentence_loss_list.append(sentence_loss)\n",
    "\n",
    "        single_ex_loss = torch.mean(torch.stack(sentence_loss_list))\n",
    "        multi_ex_loss_list.append(single_ex_loss)\n",
    "\n",
    "    batch_loss = torch.mean(torch.stack(multi_ex_loss_list))\n",
    "\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(x_val, y_val, encoder, decoder, criterion, y_idx2word):\n",
    "    with torch.no_grad():\n",
    "        bleu_score_list = []\n",
    "        val_multi_ex_loss_list = []\n",
    "        for val_ex_index, (x, y) in enumerate(zip(x_val, y_val)):\n",
    "            encoder_hidden = encoder.initHidden()\n",
    "            \n",
    "            for i in range(len(x)):\n",
    "                encoder_output, encoder_hidden = encoder(torch.tensor(x[i], device=device), encoder_hidden)\n",
    "\n",
    "            decoder_hidden = encoder_hidden\n",
    "            decoder_input = torch.tensor(SOS_token, device=device)\n",
    "            sentence_loss_list = []\n",
    "            predicted_sentences = []\n",
    "            true_sentences = []\n",
    "\n",
    "            for i in range(len(y)):\n",
    "                sentence_output = torch.empty(1, decoder.output_size, device=device)\n",
    "                predicted_words = []\n",
    "                true_words = []\n",
    "\n",
    "                for j in range(len(y[i])):\n",
    "                    deocder_output, deocder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                    sentence_output = torch.cat((sentence_output, deocder_output))\n",
    "                    topv, topi = deocder_output.topk(1)\n",
    "                    decoder_input = topi.squeeze().detach()\n",
    "                    \n",
    "                    predicted_words.append(y_idx2word[topi.item()])\n",
    "                    true_words.append(y_idx2word[y[i][j]])\n",
    "                \n",
    "                sentence_output = sentence_output[1:]\n",
    "                val_sentence_loss = criterion(sentence_output, torch.tensor(y[i], device=device))\n",
    "                sentence_loss_list.append(val_sentence_loss)\n",
    "\n",
    "                predicted_sentence_i = ' '.join(predicted_words)\n",
    "                true_sentence_i = ' '.join(true_words)\n",
    "                predicted_sentences.append(predicted_sentence_i)\n",
    "                true_sentences.append(true_sentence_i)\n",
    "\n",
    "            val_single_ex_loss = torch.mean(torch.stack(sentence_loss_list))\n",
    "            val_multi_ex_loss_list.append(val_single_ex_loss)\n",
    "                \n",
    "            bleu_score_value = bleu_score(preds=predicted_sentences, target=true_sentences)\n",
    "            bleu_score_list.append(bleu_score_value)\n",
    "        \n",
    "        val_bleu_score = torch.mean(torch.stack(bleu_score_list)).item()\n",
    "        val_loss = torch.mean(torch.stack(val_multi_ex_loss_list)).item()\n",
    "\n",
    "        return val_loss, val_bleu_score\n",
    "            \n",
    "# val_loss, val_bleu_score = val_step(x_lookup_val, y_lookup_val, encoder, decoder, criterion, y_idx2word)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_train_val_loss: 8.586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac82720834cb415688ca133f4f667cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bcc850e41340c5a786c8e6cf1956b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 7.725 \t Val Loss: 7.503 \t Val BLeU Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 10\n",
    "num_batches = len(x_lookup_train) // batch_size\n",
    "train_epoch_loss_list = []\n",
    "val_epoch_loss_list = []\n",
    "val_epoch_bleu_score_list = []\n",
    "\n",
    "pre_train_val_loss, pre_train_val_bleu_score = val_step(x_lookup_val, y_lookup_val, encoder, decoder, criterion, y_idx2word)\n",
    "print(f\"pre_train_val_loss: {pre_train_val_loss:.3f}\")\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs), desc=\"Epoch\"):\n",
    "    train_batch_loss_list = []\n",
    "    for batch in range(num_batches):\n",
    "        x_batch = x_lookup_train[batch*batch_size:(batch+1)*batch_size]\n",
    "        y_batch = y_lookup_train[batch*batch_size:(batch+1)*batch_size]\n",
    "\n",
    "        batch_loss = batch_train_step(x_batch, y_batch, encoder, decoder, criterion)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        train_batch_loss_list.append(batch_loss)\n",
    "\n",
    "    train_epoch_loss = torch.mean(torch.stack(train_batch_loss_list)).item()\n",
    "    train_epoch_loss_list.append(train_epoch_loss)\n",
    "\n",
    "    val_epoch_loss, val_bleu_score = val_step(x_lookup_val, y_lookup_val, encoder, decoder, criterion, y_idx2word)\n",
    "    val_epoch_loss_list.append(val_epoch_loss)\n",
    "    val_epoch_bleu_score_list.append(val_bleu_score)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} \\t Loss: {train_epoch_loss:.3f} \\t Val Loss: {val_epoch_loss:.3f} \\t Val BLeU Score: {val_bleu_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(x, y, x_idx2word, y_idx2word, encoder, decoder, target_length=50):\n",
    "    for i in range(len(x)):\n",
    "        x_i = x[i]\n",
    "        y_i = y[i]\n",
    "        input_length = len(x_i)\n",
    "        n_captions = len(y_i)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x_i[ei], device=device), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_sentences = []\n",
    "\n",
    "        for di in range(n_captions):\n",
    "            decoded_words = []\n",
    "            for dj in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                decoded_words.append(y_idx2word[topi.item()])\n",
    "                if topi.item() == EOS_token:\n",
    "                    is_eos = True\n",
    "                    break\n",
    "                else:\n",
    "                    is_eos = False\n",
    "\n",
    "            predicted_sentence = ' '.join(decoded_words)\n",
    "            decoded_sentences.append(predicted_sentence)\n",
    "            if is_eos:\n",
    "                break\n",
    "            \n",
    "        input_text = ' '.join([x_idx2word[word] for word in x_i])\n",
    "        target_text = ' '.join([y_idx2word[word] for word in y_i[0]])\n",
    "\n",
    "        print(f\"input: {input_text}\")\n",
    "        print(f\"target: {target_text}\")\n",
    "        print(f\"predicted: {decoded_sentences[0]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomly(x_idx2word, y_idx2word, encoder, decoder, n=1):\n",
    "    for i in range(n):\n",
    "        rand_int = random.randint(0, len(x_lookup_val))\n",
    "        x_i = x_lookup_val[rand_int]\n",
    "        y_i = y_lookup_val[rand_int]\n",
    "\n",
    "        evaluate([x_i], [y_i], x_idx2word, y_idx2word, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x_test, y_test, encoder, decoder, x_idx2word, y_idx2word, target_length=50):\n",
    "    test_loss = 0\n",
    "    test_results = []\n",
    "    bleu_score_list = []\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        test_loss_i = 0\n",
    "        x = x_test[i]\n",
    "        y = y_test[i]\n",
    "        input_length = len(x)\n",
    "        n_captions = len(y)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(torch.tensor(x[ei], device=device), encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_sentences = []\n",
    "        true_sentences = []\n",
    "\n",
    "        for di in range(n_captions):\n",
    "            decoded_words = []\n",
    "            true_words = []\n",
    "            for dj in range(target_length):\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                y_di_dj = y[di][dj] if dj < len(y[di]) else EOS_token\n",
    "                test_loss_i += criterion(decoder_output, torch.tensor(y_di_dj, device=device).view(-1))\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()\n",
    "                \n",
    "                if dj < len(y[di]):\n",
    "                    true_words.append(y_idx2word[y[di][dj]])\n",
    "\n",
    "                if topi.item() == EOS_token:\n",
    "                    is_eos = True\n",
    "                    decoded_words.append('<EOS>')\n",
    "                    break\n",
    "                else:\n",
    "                    is_eos = False\n",
    "                    decoded_words.append(y_idx2word[topi.item()])\n",
    "                \n",
    "            predicted_sentence = ' '.join(decoded_words)\n",
    "            true_sentence = ' '.join(true_words)\n",
    "            decoded_sentences.append(predicted_sentence)\n",
    "            true_sentences.append(true_sentence)\n",
    "            if is_eos:\n",
    "                break\n",
    "\n",
    "        test_loss_i = test_loss_i / n_captions\n",
    "        test_loss += test_loss_i.item()\n",
    "\n",
    "        bleu_score_i = bleu_score(preds=decoded_sentences, target=true_sentences)\n",
    "        bleu_score_list.append(bleu_score_i)\n",
    "\n",
    "        input_text = ' '.join([x_idx2word[word] for word in x])\n",
    "        target_text = ' '.join([y_idx2word[word] for word in y[0]])\n",
    "        predicted_text = decoded_sentences[0]\n",
    "\n",
    "        test_result_i = (input_text, target_text, predicted_text)\n",
    "        test_results.append(test_result_i)\n",
    "\n",
    "    test_bleu_score = torch.mean(torch.stack(bleu_score_list)).item()\n",
    "\n",
    "    return test_loss / len(x_test), test_results, test_bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: bus 009 038 087 08 <EOS>\n",
      "target: a green and white bus is on the street <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n",
      "input: person 015 025 057 093 person 041 008 048 013 surfboard 041 044 058 07 <EOS>\n",
      "target: a woman in a wet suit carrying a surfboard into the ocean <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n",
      "input: zebra 067 057 084 071 zebra 017 057 038 075 <EOS>\n",
      "target: an antilope is eating grass in between two zebra <EOS>\n",
      "predicted: a a a a a a a <EOS>\n",
      "\n",
      "input: person 057 047 079 07 <EOS>\n",
      "target: a man surfing beside a bird on a cloudy day <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n",
      "input: person 079 062 084 078 person 065 062 069 083 person 075 061 078 074 person 087 062 089 074 person 063 062 064 066 person 092 061 095 07 <EOS>\n",
      "target: people are skiing and snowboarding on a high mountain <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n",
      "input: person 022 042 028 062 person 071 031 078 065 person 042 041 049 064 person 028 041 034 061 person 05 034 057 061 person 053 054 069 081 person 061 049 069 063 skis 00 073 025 083 <EOS>\n",
      "target: people standing and sitting on snow with skis and mountain <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n",
      "input: traffic light 034 081 037 087 <EOS>\n",
      "target: a street sign that reads sparta sitting next to a tall building <EOS>\n",
      "predicted: a a a a a a a <EOS>\n",
      "\n",
      "input: bus 038 069 052 074 <EOS>\n",
      "target: a bus stop sign with a large building in the background <EOS>\n",
      "predicted: a a a a a a a <EOS>\n",
      "\n",
      "input: banana 065 032 087 072 <EOS>\n",
      "target: several fruits and veggies are ready to be eaten <EOS>\n",
      "predicted: a a a a a a a <EOS>\n",
      "\n",
      "input: chair 015 041 047 10 keyboard 035 043 06 056 laptop 058 02 084 049 laptop 021 017 041 039 tv 044 016 066 04 tv 00 015 024 04 laptop 07 045 10 081 <EOS>\n",
      "target: a desk with five computers in a row on it <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(x_lookup_val, y_lookup_val, x_idx2word, y_idx2word, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: person 022 042 028 062 person 071 031 078 065 person 042 041 049 064 person 028 041 034 061 person 05 034 057 061 person 053 054 069 081 person 061 049 069 063 skis 00 073 025 083 <EOS>\n",
      "target: people standing and sitting on snow with skis and mountain <EOS>\n",
      "predicted: a a a a a a a a <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_randomly(x_idx2word, y_idx2word, encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_results, test_bleu_score = test(x_lookup_test, y_lookup_test, encoder, decoder, x_idx2word, y_idx2word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_captioning_cleaned_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
